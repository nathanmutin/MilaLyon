{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da195a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from implementations import *\n",
    "from preprocessing import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "#data_folder = 'C:/Users/ACER/OneDrive - epfl.ch/Desktop/ML/dataset/'\n",
    "#data_folder = \"C:/Users/plane/OneDrive/Bureau/MilaLyon/data/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f71fab",
   "metadata": {},
   "source": [
    "# Loading data from CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ddbfb6",
   "metadata": {},
   "source": [
    "The file `data/default_values.csv` contains information about each feature\n",
    "\n",
    "* **feature**: name of the feature\n",
    "\n",
    "* **Value for zero**: value to replace missing values if the feature is numerical and the missing values are to be replaced by zero (ex: for `CHILDREN` 88 means 0 children)\n",
    "\n",
    "* **Combination of other indicators**: 1 if the feature is just a combination of other features (ex: `_RFHLTH` is 1 if `GENHLTH` = 1, 2 or 3 and 2 if `GENHLTH` = 4 or 5)\n",
    "\n",
    "* **Health related**: 1 if the feature is health related\n",
    "\n",
    "* **Bad format, better format elsewhere**: 1 if the feature is in a bad format but parsed in another feature\n",
    "\n",
    "* **Bad format, no better**: 1 if the feature is in a bad format and not parsed in another feature\n",
    "\n",
    "* **Values for no response**: values that indicate no response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = load_csv_data(data_folder, max_rows=1000)\n",
    "x_train, x_test, y_train, train_ids, test_ids, feature_names, zero_values, default_values, useless, health_related, better_elsewhere, bad_format_no_better = _data\n",
    "\n",
    "print(\"Number of training samples: \", x_train.shape[0]\n",
    "      , \"\\nNumber of test samples: \", x_test.shape[0]\n",
    "      , \"\\nNumber of features: \", x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485642cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas version\n",
    "# drop first column (ids)\n",
    "df_x_train = pd.read_csv(data_folder + 'x_train.csv').drop(columns=['Id'])\n",
    "df_y_train = pd.read_csv(data_folder + 'y_train.csv').drop(columns=['Id'])\n",
    "df_x_test = pd.read_csv(data_folder + 'x_test.csv').drop(columns=['Id'])\n",
    "\n",
    "# Pandas version\n",
    "print(df_x_train.info())\n",
    "print(df_x_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d293abc",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a7a88",
   "metadata": {},
   "source": [
    "## Replace default values in dataset by NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad5d80",
   "metadata": {},
   "source": [
    "Custom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb133e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Default values for _PRACE1:\", default_values['_PRACE1'])\n",
    "\n",
    "print()\n",
    "print(\"Row index | Value of _PRACE1 before replacing defaults with NaN\")\n",
    "print(\"9         |\", x_train[9,feature_names == '_PRACE1'])\n",
    "print(\"101       |\", x_train[101,feature_names == '_PRACE1'])\n",
    "print(\"202       |\", x_train[202,feature_names == '_PRACE1'])\n",
    "\n",
    "replace_default_with_nan(x_train, x_test, feature_names, default_values)\n",
    "\n",
    "print()\n",
    "print(\"Row index | Value of _PRACE1 after replacing defaults with NaN\")\n",
    "print(\"9         |\", x_train[9,feature_names == '_PRACE1'])\n",
    "print(\"101       |\", x_train[101,feature_names == '_PRACE1'])\n",
    "print(\"202       |\", x_train[202,feature_names == '_PRACE1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971526c4",
   "metadata": {},
   "source": [
    "Pandas implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Pandas\n",
    "print()\n",
    "print(\"Row index | Value of _PRACE1 before replacing defaults with NaN\")\n",
    "print(\"9         |\", df_x_train.loc[9,'_PRACE1'])\n",
    "print(\"101       |\", df_x_train.loc[101,'_PRACE1'])\n",
    "print(\"202       |\", df_x_train.loc[202,'_PRACE1'])\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    # Replace default values with NaN\n",
    "    for default_value in default_values[feature]:\n",
    "        df_x_train.loc[df_x_train[feature] == default_value, feature] = np.nan\n",
    "        df_x_test.loc[df_x_test[feature] == default_value, feature] = np.nan\n",
    "        \n",
    "print()\n",
    "print(\"Row index | Value of _PRACE1 after replacing defaults with NaN\")\n",
    "print(\"9         |\", df_x_train.loc[9,'_PRACE1'])\n",
    "print(\"101       |\", df_x_train.loc[101,'_PRACE1'])\n",
    "print(\"202       |\", df_x_train.loc[202,'_PRACE1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e510daa",
   "metadata": {},
   "source": [
    "## Identify features type (binary, categorical, continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = detect_feature_type(x_train)\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    print(f\"{i}: {feature} - {feature_types[i]}\", end=\"\")\n",
    "    if useless[i]:\n",
    "        print(\" (useless)\", end=\"\")\n",
    "    if health_related[i]:\n",
    "        print(\" (health related)\", end=\"\")\n",
    "    if better_elsewhere[i]:\n",
    "        print(\" (better elsewhere)\", end=\"\")\n",
    "    if bad_format_no_better[i]:\n",
    "        print(\" (bad format, no better)\", end=\"\")\n",
    "    if zero_values[feature] != None:\n",
    "        print(\" (zero value:\", zero_values[feature], end=\")\")\n",
    "    if len(default_values[feature]) > 0:\n",
    "        print(\" (default values:\", default_values[feature], end=\")\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43c74",
   "metadata": {},
   "source": [
    "## Plot the number of missing values per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37194e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of NaN values per feature\n",
    "nan_percentage = np.mean(np.isnan(x_train), axis=0) * 100\n",
    "# Cummulative distribution function of NaN percentages\n",
    "sorted_nan_percentage = np.sort(nan_percentage)\n",
    "plt.plot(sorted_nan_percentage, np.arange(len(sorted_nan_percentage), 0, -1))\n",
    "plt.xlabel('Percentage of NaN values per feature')\n",
    "plt.ylabel('Number of features with more than x% NaN values')\n",
    "plt.title('CCDF of NaN percentages per feature')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b82f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas version\n",
    "# Plot ccdf of NaN percentages\n",
    "nan_percentage = df_x_train.isna().mean() * 100\n",
    "sorted_nan_percentage = np.sort(nan_percentage)\n",
    "plt.plot(sorted_nan_percentage, np.arange(len(sorted_nan_percentage), 0, -1))\n",
    "plt.xlabel('Percentage of NaN values per feature')\n",
    "plt.ylabel('Number of features with more than x% NaN values')\n",
    "plt.title('CCDF of NaN percentages per feature')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875c56d",
   "metadata": {},
   "source": [
    "## Replace missing values by the mean of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bdecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputation(x_train, x_test)\n",
    "# If using pandas\n",
    "df_x_train.fillna(df_x_train.mean(), inplace=True)\n",
    "df_x_test.fillna(df_x_train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train.fillna(df_x_train.mean(), inplace=True)\n",
    "df_x_test.fillna(df_x_train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7ca80",
   "metadata": {},
   "source": [
    "## Correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix (each row is an observation, each column a feature)\n",
    "corr = np.corrcoef(x_train, rowvar=False)\n",
    "\n",
    "# Plot heatmap\n",
    "im = plt.imshow(corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label=\"Correlation\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c14782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas version\n",
    "# Compute correlation matrix (rows=features)\n",
    "corr_pd = df_x_train.corr()\n",
    "# Plot heatmap without axis ticks\n",
    "sns.heatmap(corr_pd, cmap=\"coolwarm\", vmin=-1, vmax=1, xticklabels=False, yticklabels=False)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally print highly correlated pairs\n",
    "threshold = 0.9\n",
    "print(f\"\\nHighly correlated features (|corr| > {threshold}):\")\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i + 1, corr.shape[1]):\n",
    "        if abs(corr[i, j]) > threshold:\n",
    "            print(f\"  {feature_names[i]} â†” {feature_names[j]} : {corr[i, j]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047a229",
   "metadata": {},
   "source": [
    "## Correlation between features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = np.array([np.corrcoef(x_train[:, i], y_train)[0, 1] for i in range(x_train.shape[1])])\n",
    "correlation_ranked = np.argsort(np.abs(corr_with_target))[::-1]\n",
    "\n",
    "excluded_features = []\n",
    "\n",
    "for idx in correlation_ranked:\n",
    "    if not np.isnan(corr_with_target[idx]):\n",
    "        print(f\"{feature_names[idx]}: {corr_with_target[idx]:.4f}\")\n",
    "    else:\n",
    "        excluded_features.append(feature_names[idx])\n",
    "print(\"\\nExcluded features due to NaN correlation with target:\", excluded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa693326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas version\n",
    "corr_with_target_pd = df_x_train.apply(lambda col: col.corr(df_y_train['_MICHD']))\n",
    "correlation_ranked_pd = corr_with_target_pd.abs().sort_values(ascending=False)\n",
    "\n",
    "excluded_features = []\n",
    "\n",
    "for feature, corr_value in correlation_ranked_pd.items():\n",
    "    if np.isnan(corr_value):\n",
    "        excluded_features.append(feature)\n",
    "    else:\n",
    "        print(f\"{feature}: {corr_value:.4f}\")\n",
    "        \n",
    "print(\"\\nExcluded features due to NaN correlation with target:\", excluded_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b575179",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859150a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca, eigvecs, explained_variance = pca_reduce(x_train, variance_threshold=1-1e-6)\n",
    "\n",
    "plt.bar(np.arange(1, len(explained_variance) + 1), explained_variance)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d89881",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.arange(1, len(cumulative_variance) + 1), cumulative_variance, 'o-', linewidth=2)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% variance threshold')\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad479fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas and sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca_reduce = pca.fit_transform(df_x_train.fillna(df_x_train.mean()))\n",
    "\n",
    "# Plot the explained variance ratio, y log scale\n",
    "plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio of Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f7b53",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Still in progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = (y_train == 1).astype(int)\n",
    "\n",
    "# add constant bias feature (column of ones)\n",
    "const_train = np.ones((x_train.shape[0], 1))\n",
    "const_test = np.ones((x_test.shape[0], 1))\n",
    "x_train = np.hstack((x_train, const_train))\n",
    "x_test = np.hstack((x_test, const_test))\n",
    "\n",
    "max_iters = 1000      # number of gradient descent steps\n",
    "gamma = 0.0001       # learning rate\n",
    "\n",
    "initial_w = np.zeros(x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "print(f\"Final training loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec41b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(tx, w, threshold=0.5):\n",
    "    pred = sigmoid(tx @ w)\n",
    "    return (pred >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = predict_labels(x_train, w)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "acc_train = compute_accuracy(y_train_bin, y_pred_train)\n",
    "\n",
    "print(f\"Training accuracy: {acc_train*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set and save predictions\n",
    "y_pred_test = 2*predict_labels(x_test, w) - 1\n",
    "create_csv_submission(test_ids, y_pred_test, 'logistic_regression_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310dffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# add constant bias feature (column of ones)\n",
    "df_x_train['_CONST'] = 1\n",
    "df_x_test['_CONST'] = 1\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(df_x_train, df_y_train.values.ravel())\n",
    "\n",
    "# percentage of correct predictions\n",
    "y_pred_train = model.predict(df_x_train)\n",
    "accuracy = np.mean(y_pred_train == df_y_train.values.ravel())\n",
    "print(f\"Training accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(50, 20), max_iter=1000)\n",
    "model.fit(df_x_train, df_y_train.values.ravel())\n",
    "\n",
    "# Performance on training set\n",
    "y_pred_train = model.predict(df_x_train)\n",
    "accuracy = np.mean(y_pred_train == df_y_train.values.ravel())\n",
    "print(f\"Training accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with kernel\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "model.fit(df_x_train, df_y_train.values.ravel())\n",
    "# Performance on training set\n",
    "y_pred_train = model.predict(df_x_train)\n",
    "accuracy = np.mean(y_pred_train == df_y_train.values.ravel())\n",
    "print(f\"Training accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "y_pred_test = model.predict(df_x_test)\n",
    "create_csv_submission(test_ids, y_pred_test, 'logistic_regression_sklearn_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
